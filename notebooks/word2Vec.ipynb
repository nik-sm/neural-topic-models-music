{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.utils as gu\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/lyrics.csv\").dropna(0, subset=[\"lyrics\",\"genre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "badWords = [\"verse\", \"chorus\"]\n",
    "def doWork(song, songIDX):\n",
    "    if not pd.isnull(song):\n",
    "        return [w for w in gu.simple_preprocess(song) if w not in badWords], songIDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusAndGenres = Parallel(n_jobs=4)(delayed(doWork)(song, i) for i, song in enumerate(df[\"lyrics\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [t[0] for t in corpusAndGenres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/miniconda3/envs/py36/lib/python3.6/site-packages/pandas/core/series.py:942: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    }
   ],
   "source": [
    "genres = df[\"genre\"][[t[1] for t in corpusAndGenres]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/corpus.npy\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/genres.npy\", genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/miniconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "oneHotGenres = enc.fit_transform(df[\"genre\"].values.reshape((-1,1)))\n",
    "oneHotGenres = oneHotGenres.toarray()\n",
    "leGenres = LabelEncoder().fit_transform(df[\"genre\"].values.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(corpus, size=300, window=5, min_count=1, workers=4, callbacks=[EpochLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../data/word2Vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'beyonce'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"beyonce anye Jay-Z\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/word2Vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(444256779, 571649240)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(corpus, total_examples=model.corpus_count, epochs=10, callbacks=[EpochLogger()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, StratifiedKFold, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import cProfile\n",
    "import re\n",
    "from io import  StringIO\n",
    "import pstats\n",
    "import argparse\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "def getMedianModel(li):\n",
    "    med = np.median([l[1] for l in li])\n",
    "    shifted = [np.abs(l[1] - med) for l in li]\n",
    "    medianIDX = np.argmin(shifted)\n",
    "    return li[medianIDX][0]\n",
    "\n",
    "\n",
    "def newPipe(features, labels, iters=10, regularization=\"l2\"):\n",
    "    experimentDict = {}\n",
    "    # Parameter Grid for hyper-parameter tuning\n",
    "    paramGrid = {'C': np.logspace(-4, 4, num=10)}\n",
    "    splits = 5 # Number of folds in Repeated Stratified K-Fold CV (RSKFCV)\n",
    "    repeats = 5 # Number of repeats in Repeated Stratified K-Fold CV (RSKFCV)\n",
    "    experimentDict[\"paramGrid\"] = paramGrid\n",
    "    experimentDict[\"RSKFCV splits\"] = splits\n",
    "    experimentDict[\"RSKFCV repeats\"] = repeats\n",
    "    experimentDict[\"regularization\"] = regularization\n",
    "    experimentDict[\"iterDict\"] = []\n",
    "    xTrainVal, xTestRaw, yTrainVal, yTestRaw = train_test_split(features, labels, test_size=0.2)\n",
    "    for iteration in range(iters):\n",
    "        print(\"iteration {} of {}\".format(iteration, iters))\n",
    "        dict_i = {}\n",
    "        # store experiment information on first iteration\n",
    "        if iteration == 0:\n",
    "            experimentDict[\"xTrainVal\"] = xTrainVal\n",
    "            experimentDict[\"yTrainVal\"] = yTrainVal\n",
    "        rskf = RepeatedStratifiedKFold(n_splits=splits, n_repeats=repeats)\n",
    "        # Store model perf on train and val data for model with each hyper-parameter assignment for all train/val splits\n",
    "        trainRows = []\n",
    "        valRows = []\n",
    "        for train_index, validation_index in rskf.split(xTrainVal, yTrainVal):\n",
    "            # Separate train and val data for a single run in Repeated Stratified K-Fold CV (RSKFCV)\n",
    "            xTrain = xTrainVal[train_index]\n",
    "            yTrain = yTrainVal[train_index]\n",
    "            xVal = xTrainVal[validation_index]\n",
    "            yVal = yTrainVal[validation_index]\n",
    "            # Store performance in train and val data for each hyper-parameter assignment\n",
    "            trainRow = []\n",
    "            valRow = []\n",
    "            for cNum, c in enumerate(paramGrid[\"C\"]):\n",
    "                if regularization == \"l2\":\n",
    "                    logReg = LogisticRegression(penalty=\"l2\", class_weight='balanced', C=c, solver='lbfgs',multi_class='multinomial')\n",
    "                elif regularization == \"l1\":\n",
    "                    logReg = LogisticRegression(penalty=\"l1\", class_weight='balanced', C=c, solver='lbfgs',multi_class='multinomial')\n",
    "                else:\n",
    "                    assert False, \"{} regularization is not supported\".format(regularization)\n",
    "                logReg.fit(xTrain, yTrain)\n",
    "                trainProbs = logReg.predict_proba(xTrain)\n",
    "                yPred = np.argmax(trainProbs, axis=1)\n",
    "                trainF1 = f1_score(yTrain, yPred, average=\"weighted\")\n",
    "                valProbs = logReg.predict_proba(xVal)\n",
    "                valPred = np.argmax(valProbs, axis=1)\n",
    "                valF1 = f1_score(yVal, valPred, average=\"weighted\")\n",
    "                # store the performance for this c val on this train val split\n",
    "                trainRow.append(trainF1)\n",
    "                valRow.append(valF1)\n",
    "            # store the performance for this train/val split\n",
    "            valRows.append(valRow)\n",
    "            trainRows.append(trainRow)\n",
    "        # From results of RSKFCV figure out optimal c-value\n",
    "        trainRows = np.array(trainRows)\n",
    "        valRows = np.array(valRows)\n",
    "        trainMean = np.mean(trainRows, axis=0)\n",
    "        valMean = np.mean(valRows, axis=0)\n",
    "        chosenCIDX = np.argmax(valMean)\n",
    "        chosenC = paramGrid[\"C\"][chosenCIDX]\n",
    "        dict_i[\"chosen c value\"] = chosenC\n",
    "        dict_i[\"cv train f1\"] = trainRows\n",
    "        dict_i[\"cv val f1\"] = valRows\n",
    "        # Retrain model using all train and validation data using optimal C value\n",
    "        if regularization == \"l2\":\n",
    "            fullLogReg = LogisticRegression(penalty=\"l2\", class_weight='balanced', C=chosenC, solver='lbfgs',multi_class='multinomial')\n",
    "        elif regularization == \"l1\":\n",
    "            fullLogReg = LogisticRegression(penalty=\"l1\", class_weight='balanced', C=chosenC, solver='lbfgs',multi_class='multinomial')\n",
    "        else:\n",
    "            assert False, \"{} regularization is not supported\".format(regularization)\n",
    "        fullLogReg.fit(xTrainVal, yTrainVal)\n",
    "        dict_i[\"full model coefficients\"] = fullLogReg.coef_\n",
    "        dict_i[\"full model intercept\"] = fullLogReg.intercept_\n",
    "        dict_i[\"full model n_iter_\"] = fullLogReg.n_iter_\n",
    "        # get bootstrapped test set for this iteration\n",
    "        xTest, yTest = resample(xTestRaw,yTestRaw, replace=True, random_state=iteration)\n",
    "        dict_i[\"xTest\"] = xTest\n",
    "        dict_i[\"yTest\"] = yTest\n",
    "        # get predictions for test set\n",
    "        testProbs = fullLogReg.predict_proba(xTest)\n",
    "        dict_i[\"testProbs\"] = testProbs\n",
    "        # Calculate Test Performance\n",
    "        testF1 = f1_score(yTest, np.argmax(testProbs, axis=1), average=\"weighted\")\n",
    "        dict_i[\"testF1\"] = testF1\n",
    "        experimentDict[\"iterDict\"].append(dict_i)\n",
    "    return experimentDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/Users/danielzeiberg/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/Users/danielzeiberg/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/Users/danielzeiberg/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "[]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-626e70d9fc6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvecAvg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msong\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mallVecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: []"
     ]
    }
   ],
   "source": [
    "vecSums = []\n",
    "vecAvg = []\n",
    "for song in corpus:\n",
    "    assert len(song), song\n",
    "    vec = model[song[0]]\n",
    "    allVecs = [model[song[0]]]\n",
    "    for wordIDX in range(1,len(song)):\n",
    "        vec = vec + model[song[wordIDX]]\n",
    "        allVecs.append(model[song[wordIDX]])\n",
    "    vecSums.append(vec)\n",
    "    arr= np.array(allVecs)\n",
    "    vecAvg.append(np.mean(arr, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "index                                                  3974\nsong                                           aaeun-ainoii\nyear                                                   2006\nartist                                  dicaiaaoi-aeaenaiad\ngenre                                         Not Available\nlyrics    -.\\n,\\n.\\n,\\n,\\n, ...\\n, .\\n.\\n, ,\\n-.\\n, :\\n\"...\nName: 3974, dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-611ea8a2042e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: index                                                  3974\nsong                                           aaeun-ainoii\nyear                                                   2006\nartist                                  dicaiaaoi-aeaenaiad\ngenre                                         Not Available\nlyrics    -.\\n,\\n.\\n,\\n,\\n, ...\\n, .\\n.\\n, ,\\n-.\\n, :\\n\"...\nName: 3974, dtype: object"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(corpus):\n",
    "    assert len(c), df.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
