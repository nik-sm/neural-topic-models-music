{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\n",
    "    [\"yeezy\", \"season\", \"approaching\"],\n",
    "    [\"this\", \"is\", \"a\", \"story\", \"about\", \"a\", \"girl\"],\n",
    "    [\"Stacy's\", \"Mom\", \"has\", \"got\", \"it\", \"going\", \"on\"]\n",
    "]\n",
    "stringCorpus=[\" \".join(s) for s in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(stringCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'approaching',\n",
       " 'girl',\n",
       " 'going',\n",
       " 'got',\n",
       " 'has',\n",
       " 'is',\n",
       " 'it',\n",
       " 'mom',\n",
       " 'on',\n",
       " 'season',\n",
       " 'stacy',\n",
       " 'story',\n",
       " 'this',\n",
       " 'yeezy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['yeezy', 'season', 'approaching'], dtype='<U11')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Song Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.load(\"../data/corpus.npy\")\n",
    "genres = np.load(\"../data/genres.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "songStringCorpus = [\" \".join(song) for song in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "songVectorizer = TfidfVectorizer()\n",
    "songTFIDF = songVectorizer.fit_transform(songStringCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "leGenres = LabelEncoder().fit_transform(genres.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, StratifiedKFold, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import cProfile\n",
    "import re\n",
    "from io import  StringIO\n",
    "import pstats\n",
    "import argparse\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "def getMedianModel(li):\n",
    "    med = np.median([l[1] for l in li])\n",
    "    shifted = [np.abs(l[1] - med) for l in li]\n",
    "    medianIDX = np.argmin(shifted)\n",
    "    return li[medianIDX][0]\n",
    "\n",
    "\n",
    "def newPipe(features, labels, iters=10, regularization=\"l2\"):\n",
    "    experimentDict = {}\n",
    "    # Parameter Grid for hyper-parameter tuning\n",
    "    paramGrid = {'C': np.logspace(-4, 4, num=10)}\n",
    "    splits = 5 # Number of folds in Repeated Stratified K-Fold CV (RSKFCV)\n",
    "    repeats = 5 # Number of repeats in Repeated Stratified K-Fold CV (RSKFCV)\n",
    "    experimentDict[\"paramGrid\"] = paramGrid\n",
    "    experimentDict[\"RSKFCV splits\"] = splits\n",
    "    experimentDict[\"RSKFCV repeats\"] = repeats\n",
    "    experimentDict[\"regularization\"] = regularization\n",
    "    experimentDict[\"iterDict\"] = []\n",
    "    xTrainVal, xTestRaw, yTrainVal, yTestRaw = train_test_split(features, labels, test_size=0.2)\n",
    "    for iteration in range(iters):\n",
    "        print(\"iteration {} of {}\".format(iteration, iters))\n",
    "        dict_i = {}\n",
    "        # store experiment information on first iteration\n",
    "        if iteration == 0:\n",
    "            experimentDict[\"xTrainVal\"] = xTrainVal\n",
    "            experimentDict[\"yTrainVal\"] = yTrainVal\n",
    "        rskf = RepeatedStratifiedKFold(n_splits=splits, n_repeats=repeats)\n",
    "        # Store model perf on train and val data for model with each hyper-parameter assignment for all train/val splits\n",
    "        trainRows = []\n",
    "        valRows = []\n",
    "        for train_index, validation_index in rskf.split(xTrainVal, yTrainVal):\n",
    "            # Separate train and val data for a single run in Repeated Stratified K-Fold CV (RSKFCV)\n",
    "            xTrain = xTrainVal[train_index]\n",
    "            yTrain = yTrainVal[train_index]\n",
    "            xVal = xTrainVal[validation_index]\n",
    "            yVal = yTrainVal[validation_index]\n",
    "            # Store performance in train and val data for each hyper-parameter assignment\n",
    "            trainRow = []\n",
    "            valRow = []\n",
    "            for cNum, c in enumerate(paramGrid[\"C\"]):\n",
    "                if regularization == \"l2\":\n",
    "                    logReg = LogisticRegression(penalty=\"l2\", class_weight='balanced', C=c, solver='lbfgs',multi_class='multinomial')\n",
    "                elif regularization == \"l1\":\n",
    "                    logReg = LogisticRegression(penalty=\"l1\", class_weight='balanced', C=c, solver='lbfgs',multi_class='multinomial')\n",
    "                else:\n",
    "                    assert False, \"{} regularization is not supported\".format(regularization)\n",
    "                logReg.fit(xTrain, yTrain)\n",
    "                trainProbs = logReg.predict_proba(xTrain)\n",
    "                yPred = np.argmax(trainProbs, axis=1)\n",
    "                trainF1 = f1_score(yTrain, yPred, average=\"weighted\")\n",
    "                valProbs = logReg.predict_proba(xVal)\n",
    "                valPred = np.argmax(valProbs, axis=1)\n",
    "                valF1 = f1_score(yVal, valPred, average=\"weighted\")\n",
    "                # store the performance for this c val on this train val split\n",
    "                trainRow.append(trainF1)\n",
    "                valRow.append(valF1)\n",
    "            # store the performance for this train/val split\n",
    "            valRows.append(valRow)\n",
    "            trainRows.append(trainRow)\n",
    "        # From results of RSKFCV figure out optimal c-value\n",
    "        trainRows = np.array(trainRows)\n",
    "        valRows = np.array(valRows)\n",
    "        trainMean = np.mean(trainRows, axis=0)\n",
    "        valMean = np.mean(valRows, axis=0)\n",
    "        chosenCIDX = np.argmax(valMean)\n",
    "        chosenC = paramGrid[\"C\"][chosenCIDX]\n",
    "        dict_i[\"chosen c value\"] = chosenC\n",
    "        dict_i[\"cv train f1\"] = trainRows\n",
    "        dict_i[\"cv val f1\"] = valRows\n",
    "        # Retrain model using all train and validation data using optimal C value\n",
    "        if regularization == \"l2\":\n",
    "            fullLogReg = LogisticRegression(penalty=\"l2\", class_weight='balanced', C=chosenC, solver='lbfgs',multi_class='multinomial')\n",
    "        elif regularization == \"l1\":\n",
    "            fullLogReg = LogisticRegression(penalty=\"l1\", class_weight='balanced', C=chosenC, solver='lbfgs',multi_class='multinomial')\n",
    "        else:\n",
    "            assert False, \"{} regularization is not supported\".format(regularization)\n",
    "        fullLogReg.fit(xTrainVal, yTrainVal)\n",
    "        dict_i[\"full model coefficients\"] = fullLogReg.coef_\n",
    "        dict_i[\"full model intercept\"] = fullLogReg.intercept_\n",
    "        dict_i[\"full model n_iter_\"] = fullLogReg.n_iter_\n",
    "        # get bootstrapped test set for this iteration\n",
    "        xTest, yTest = resample(xTestRaw,yTestRaw, replace=True, random_state=iteration)\n",
    "        dict_i[\"xTest\"] = xTest\n",
    "        dict_i[\"yTest\"] = yTest\n",
    "        # get predictions for test set\n",
    "        testProbs = fullLogReg.predict_proba(xTest)\n",
    "        dict_i[\"testProbs\"] = testProbs\n",
    "        # Calculate Test Performance\n",
    "        testF1 = f1_score(yTest, np.argmax(testProbs, axis=1), average=\"weighted\")\n",
    "        dict_i[\"testF1\"] = testF1\n",
    "        experimentDict[\"iterDict\"].append(dict_i)\n",
    "    return experimentDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 of 10\n"
     ]
    }
   ],
   "source": [
    "newPipe(songTFIDF, leGenres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
